# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Kt8qO-kt-jcg5m6YQhaOV44by9YO72sR
"""

#day-1

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df = pd.read_csv('student-mat.csv', sep=';')

print("Initial Shape:", df.shape)
print("Columns:", df.columns)
print("Missing values:\n", df.isnull().sum())

df = df.dropna()

categorical_cols = df.select_dtypes(include='object').columns.tolist()
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

df_encoded['GPA'] = df_encoded[['G1', 'G2', 'G3']].mean(axis=1)
max_absence = df_encoded['absences'].max()
df_encoded['attendance_rate'] = 1 - (df_encoded['absences'] / max_absence)
df_encoded['grade_improvement'] = df_encoded['G3'] - df_encoded['G1']
df_encoded['dropout'] = ((df_encoded['GPA'] < 5) | (df_encoded['absences'] > 15)).astype(int)

df_encoded.to_csv('student_data_processed.csv', index=False)
print("Processed data saved.")

sns.set(style="whitegrid")
plt.figure(figsize=(8, 5))
sns.boxplot(x='dropout', y='GPA', data=df_encoded)
plt.title('GPA vs Dropout')
plt.show()

plt.figure(figsize=(8, 5))
sns.boxplot(x='dropout', y='absences', data=df_encoded)
plt.title('Absences vs Dropout')
plt.show()



plt.figure(figsize=(12, 8))
sns.heatmap(df_encoded[['GPA', 'absences', 'studytime', 'failures',
                        'attendance_rate', 'grade_improvement', 'dropout']].corr(),
            annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

#day-2

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingRegressor
from sklearn.preprocessing import StandardScaler

X_clf = df_encoded.drop(columns=['dropout', 'GPA'])
y_clf = df_encoded['dropout']

X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(
    X_clf, y_clf, test_size=0.2, random_state=42)
clf = RandomForestClassifier(n_estimators=100, random_state=42)
clf.fit(X_train_clf, y_train_clf)
y_pred_clf = clf.predict(X_test_clf)

#day-3

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.metrics import (
    classification_report,
    confusion_matrix,
    accuracy_score,
    f1_score,
    mean_absolute_error,
    mean_squared_error,
    r2_score
)
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingRegressor

import shap

RANDOM_STATE = 42

df = pd.read_csv('student-mat.csv', sep=';')

df = df.dropna()

categorical_cols = df.select_dtypes(include='object').columns.tolist()
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=True)

df_encoded['GPA'] = df_encoded[['G1', 'G2', 'G3']].mean(axis=1)
max_absence = df_encoded['absences'].max()
df_encoded['attendance_rate'] = 1 - (df_encoded['absences'] / max_absence)
df_encoded['grade_improvement'] = df_encoded['G3'] - df_encoded['G1']
df_encoded['dropout'] = ((df_encoded['GPA'] < 5) | (df_encoded['absences'] > 15)).astype(int)

X_clf = df_encoded.drop(columns=['dropout', 'GPA'])
y_clf = df_encoded['dropout']

X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(
    X_clf, y_clf, test_size=0.2, random_state=RANDOM_STATE)

X_reg = df_encoded.drop(columns=['dropout', 'GPA'])
y_reg = df_encoded['GPA']

X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(
    X_reg, y_reg, test_size=0.2, random_state=RANDOM_STATE)

clf = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)
clf.fit(X_train_clf, y_train_clf)
y_pred_clf = clf.predict(X_test_clf)

reg = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=RANDOM_STATE)
reg.fit(X_train_reg, y_train_reg)
y_pred_reg = reg.predict(X_test_reg)

print("\n--- Dropout Classification ---")
clf_accuracy = accuracy_score(y_test_clf, y_pred_clf)
clf_f1 = f1_score(y_test_clf, y_pred_clf)

print("Classification Report:\n", classification_report(y_test_clf, y_pred_clf))
print("Confusion Matrix:\n", confusion_matrix(y_test_clf, y_pred_clf))
print(f"Accuracy: {clf_accuracy:.2%}")
print(f"F1 Score: {clf_f1:.2f}")

cm = confusion_matrix(y_test_clf, y_pred_clf)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False,
            xticklabels=["No Dropout", "Dropout"],
            yticklabels=["No Dropout", "Dropout"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix - Dropout Classifier")
plt.tight_layout()
plt.show()

mae = mean_absolute_error(y_test_reg, y_pred_reg)
rmse = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg))
r2 = r2_score(y_test_reg, y_pred_reg)

print("\n--- GPA Regression ---")
print(f"MAE: {mae:.2f}")
print(f"RMSE: {rmse:.2f}")
print(f"RÂ² Score: {r2:.4f}")

plt.figure(figsize=(6,6))
plt.scatter(y_test_reg, y_pred_reg, alpha=0.6)
plt.plot([0, 20], [0, 20], '--', color='red')
plt.xlabel("Actual GPA")
plt.ylabel("Predicted GPA")
plt.title("Predicted vs Actual GPA")
plt.tight_layout()
plt.show()

importances = pd.Series(clf.feature_importances_, index=X_clf.columns).sort_values(ascending=False)

print("\nTop 10 Features (Classifier Importance):\n", importances.head(10))

plt.figure(figsize=(8,5))
sns.barplot(x=importances.head(10), y=importances.head(10).index, palette="viridis")
plt.title("Top 10 Important Features Predicting Dropout")
plt.xlabel("Importance")
plt.tight_layout()
plt.show()

print(" Recommendations for School Intervention")
print("- Students with high absences and low G1/G2 grades are at highest dropout risk.")
print("- Early alerts and parent meetings should be prioritized for these students.")
print("- Improving study time and engagement can significantly improve GPA.")
print("- SHAP explanations can help build trust by showing why each student is high risk.")

import shap

X_test_clf_clean = X_test_clf.apply(pd.to_numeric, errors='coerce').fillna(0).astype(float).values
X_test_reg_clean = X_test_reg.apply(pd.to_numeric, errors='coerce').fillna(0).astype(float).values

print("\nComputing SHAP values for classifier...")

explainer_clf = shap.Explainer(clf)
shap_values_clf = explainer_clf(X_test_clf_clean)

shap.summary_plot(shap_values_clf, X_test_clf, plot_type="bar")

shap.summary_plot(shap_values_clf, X_test_clf)

print("\nComputing SHAP values for regressor...")

explainer_reg = shap.Explainer(reg)
shap_values_reg = explainer_reg(X_test_reg_clean)

shap.summary_plot(shap_values_reg, X_test_reg, plot_type="bar")

shap.summary_plot(shap_values_reg, X_test_reg)

#Bonus

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, DBSCAN

clustering_features = df_encoded[["GPA", "absences", "studytime", "failures"]]

scaler = StandardScaler()
X_cluster = scaler.fit_transform(clustering_features)

kmeans = KMeans(n_clusters=3, random_state=42)
kmeans_labels = kmeans.fit_predict(X_cluster)
df_encoded["kmeans_cluster"] = kmeans_labels

dbscan = DBSCAN(eps=1.2, min_samples=5)
dbscan_labels = dbscan.fit_predict(X_cluster)
df_encoded["dbscan_cluster"] = dbscan_labels

plt.figure(figsize=(8,5))
sns.scatterplot(
    x=df_encoded["GPA"],
    y=df_encoded["absences"],
    hue=df_encoded["kmeans_cluster"],
    palette="Set2"
)
plt.title("KMeans Clusters of Students")
plt.xlabel("GPA")
plt.ylabel("Absences")
plt.show()

